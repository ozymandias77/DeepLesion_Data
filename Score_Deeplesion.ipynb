{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Score_Deeplesion.ipynb","provenance":[],"authorship_tag":"ABX9TyMSKQ+MoZapGOkwEk63cPbU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uftF8X1PXJws","executionInfo":{"status":"ok","timestamp":1647872551131,"user_tz":240,"elapsed":20255,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}},"outputId":"7ac9780f-e4db-4200-fa67-1922d9177ceb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import pathlib\n","# Clone the tensorflow models repository if it doesn't already exist\n","if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone --depth 1 https://github.com/tensorflow/models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHL8_J6yXUzg","executionInfo":{"status":"ok","timestamp":1647872565537,"user_tz":240,"elapsed":4896,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}},"outputId":"1eefa287-c68f-47f1-e980-a8caf68c4ecd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 3468, done.\u001b[K\n","remote: Counting objects: 100% (3468/3468), done.\u001b[K\n","remote: Compressing objects: 100% (2785/2785), done.\u001b[K\n","remote: Total 3468 (delta 1043), reused 1525 (delta 634), pack-reused 0\u001b[K\n","Receiving objects: 100% (3468/3468), 34.30 MiB | 18.02 MiB/s, done.\n","Resolving deltas: 100% (1043/1043), done.\n"]}]},{"cell_type":"code","source":["# Install the Object Detection API\n","%%bash\n","cd models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-AhL4gaXXim","executionInfo":{"status":"ok","timestamp":1647872615118,"user_tz":240,"elapsed":42700,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}},"outputId":"e9ea0f30-2149-4187-fed8-77aa7b6a9f01"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/models/research\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.37.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","Collecting tensorflow_io\n","  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.10)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.55.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.63.0)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.24.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.44.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting cloudpickle<3,>=2.0.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Collecting protobuf>=3.12.0\n","  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.12)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, seqeval\n","  Building wheel for object-detection (setup.py): started\n","  Building wheel for object-detection (setup.py): finished with status 'done'\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1686356 sha256=2b42a84d9d6807cc5ede2e27af01cc4cd074146cf300dd643488a9080ba31b5f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-xala3sfa/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py): started\n","  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=cf30b563345e1401a4a08852f4103994d2cfa06f24d613eed37d719a553cc067\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for dill (setup.py): started\n","  Building wheel for dill (setup.py): finished with status 'done'\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=0b3cea9d95d1b40b1a67b7d4d0871376f727ab17212553e1a10a6bd0c3eb81d8\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py): started\n","  Building wheel for avro-python3 (setup.py): finished with status 'done'\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=f26b9ee54b27133f5d21b83a1474e203a7ee58896652411c74b85559d9f5bff6\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for seqeval (setup.py): started\n","  Building wheel for seqeval (setup.py): finished with status 'done'\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=aea0cb40465284ac651a663ad7436237468b09d9827c9477393a401e7ec96ebd\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo dill avro-python3 seqeval\n","Installing collected packages: requests, protobuf, tf-estimator-nightly, portalocker, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.0.2\n","    Uninstalling pymongo-4.0.2:\n","      Successfully uninstalled pymongo-4.0.2\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","Successfully installed apache-beam-2.37.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.10 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.7 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.19.4 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-io-0.24.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n"]},{"output_type":"stream","name":"stderr","text":["  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n","ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"]}]},{"cell_type":"code","source":["import matplotlib\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import random\n","import io\n","import imageio\n","import glob\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import colab_utils\n","from object_detection.builders import model_builder\n","\n","%matplotlib inline\n","\n","def plot_detections(image_np,\n","                    boxes,\n","                    classes,\n","                    scores,\n","                    category_index,\n","                    figsize=(12, 16),\n","                    image_name=None):\n","  \"\"\"Wrapper function to visualize detections.\n","\n","  Args:\n","    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n","    boxes: a numpy array of shape [N, 4]\n","    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n","      and match the keys in the label map.\n","    scores: a numpy array of shape [N] or None.  If scores=None, then\n","      this function assumes that the boxes to be plotted are groundtruth\n","      boxes and plot all boxes as black with no classes or scores.\n","    category_index: a dict containing category dictionaries (each holding\n","      category index `id` and category name `name`) keyed by category indices.\n","    figsize: size for the figure.\n","    image_name: a name for the image file.\n","  \"\"\"\n","  image_np_with_annotations = image_np.copy()\n","  viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_np_with_annotations,\n","      boxes,\n","      classes,\n","      scores,\n","      category_index,\n","      use_normalized_coordinates=True,\n","      min_score_thresh=0.1)\n","  if image_name:\n","    plt.imsave(image_name, image_np_with_annotations)\n","  else:\n","    plt.imshow(image_np_with_annotations)"],"metadata":{"id":"nHx_HrBgXafg","executionInfo":{"status":"ok","timestamp":1647874465899,"user_tz":240,"elapsed":314,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["NUM_CLASSES = 8\n","\n","category_index = {1: {'id': 1, 'name': 'bone'},\n","                  2: {'id': 2, 'name': 'abdomen'},\n","                  3: {'id': 3, 'name': 'mediastinum'},\n","                  4: {'id': 4, 'name': 'liver'},\n","                  5: {'id': 5, 'name': 'lung'},\n","                  6: {'id': 6, 'name': 'kidney'},\n","                  7: {'id': 7, 'name': 'soft_tissue'},\n","                  8: {'id': 8, 'name': 'pelvis'}}\n","\n","def _parse_function(example_proto):\n","    feature_description = {\n","        'image/height': tf.io.FixedLenFeature((), tf.int64, default_value=1),\n","        'image/width': tf.io.FixedLenFeature((), tf.int64, default_value=1),\n","        'image/win_min': tf.io.FixedLenFeature((), tf.float32, default_value=-1024.),\n","        'image/win_max': tf.io.FixedLenFeature((), tf.float32, default_value=3071.), \n","        'image/filename': tf.io.FixedLenFeature((), tf.string, default_value=''),\n","        'image/source_id': tf.io.FixedLenFeature((), tf.string, default_value=''),    \n","        'image/encoded': tf.io.FixedLenFeature((), tf.string, default_value=''),\n","        'image/format': tf.io.FixedLenFeature((), tf.string, default_value='jpeg'),\n","        # Object boxes and classes.\n","        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n","        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n","        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n","        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n","        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n","        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n","    }  \n","    return tf.io.parse_single_example(example_proto, feature_description)\n","\n","def GetImageLabelBoxTensors(image_features, batch_size):\n","    train_image_tensors = []\n","    gt_box_tensors = []\n","    gt_classes_one_hot_tensors = [] \n","    num_classes = NUM_CLASSES\n","    label_id_offset = 1\n","    for i in range(batch_size):\n","#       print('i = {}'.format(i))\n","        image = tf.io.decode_png(image_features['image/encoded'][i], channels=3)\n","        image = tf.cast(image, tf.float32)\n","        image = tf.expand_dims(image, axis=0)\n","        xmins = tf.sparse.to_dense(image_features['image/object/bbox/xmin'])[i:i+1]\n","        xmaxs = tf.sparse.to_dense(image_features['image/object/bbox/xmax'])[i:i+1]\n","        ymins = tf.sparse.to_dense(image_features['image/object/bbox/ymin'])[i:i+1]\n","        ymaxs = tf.sparse.to_dense(image_features['image/object/bbox/ymax'])[i:i+1]\n","        bbox = tf.concat([ymins, xmins, ymaxs, xmaxs], 0)        \n","        bbox = tf.transpose(bbox)\n","        labels_np = tf.sparse.to_dense(image_features['image/object/class/label'])[i].numpy()\n","        zero_args = np.argwhere(labels_np == 0)\n","        if zero_args.size > 0:\n","            num_bbox = zero_args[0][0]\n","            labels_np = labels_np[:num_bbox]\n","            bbox = bbox[:num_bbox] \n","#            print('labels = {}'.format(labels_np))\n","        zero_indexed_groundtruth_classes = tf.convert_to_tensor(labels_np - label_id_offset)\n","        gt_classes_one_hot_tensors.append(tf.one_hot(zero_indexed_groundtruth_classes, num_classes))\n","        train_image_tensors.append(image)\n","        gt_box_tensors.append(bbox)    \n","    return train_image_tensors, gt_box_tensors, gt_classes_one_hot_tensors\n","\n","# Again, uncomment this decorator if you want to run inference eagerly\n","@tf.function\n","def detect(input_tensor):\n","\n","    \"\"\"Run detection on an input image.\n","    Args:\n","    input_tensor: A [1, height, width, 3] Tensor of type tf.float32.\n","    Note that height and width can be anything since the image will be\n","    immediately resized according to the needs of the model within this\n","    function.\n","\n","    Returns:\n","    A dict containing 3 Tensors (`detection_boxes`, `detection_classes`,\n","    and `detection_scores`).\n","    \"\"\"\n","    preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n","    prediction_dict = detection_model.predict(preprocessed_image, shapes)\n","    return detection_model.postprocess(prediction_dict, shapes)\n","\n","def get_latest_ckpt(dir):\n","    search = dir + '/*.index'\n","    ckpts = glob.glob(search)\n","    lastest_ckpt = ''\n","    max_idx = -1\n","    for item in ckpts:\n","        item1 = item[:item.index('.')]\n","        idx = int(item1[item1.index('-')+1:])\n","        #print(item1, idx)\n","        if (idx > max_idx):\n","            max_idx = idx\n","            lastest_ckpt = item1\n","    return lastest_ckpt\n","\n","# bbox[ymin, xmin, ymax, xmax]\n","def get_iou(bbox1, bbox2):\n","    if (bbox1[1] > bbox2[3] or bbox2[1] > bbox1[3] or bbox1[0] > bbox2[2] or bbox2[0] > bbox1[2]):\n","        return 0.0\n","    overlap = ((min(bbox1[3], bbox2[3]) - max(bbox1[1], bbox2[1])) * (min(bbox1[2], bbox2[2]) - max(bbox1[0], bbox2[0])))\n","    union = ((bbox1[3] - bbox1[1]) * (bbox1[2] - bbox1[0]) + (bbox2[3] - bbox2[1]) * (bbox2[2] - bbox2[0]) - overlap)\n","#    print('overlap = {}, union = {}, ret = {}'.format(overlap, union, overlap/union))\n","    return overlap / union\n","\n","def box1in2(bbox1, bbox2):\n","    cx = (bbox1[1] + bbox1[3]) / 2\n","    cy = (bbox1[0] + bbox1[2]) / 2\n","    return (cy > bbox2[0] and cy < bbox2[2] and cx > bbox2[1] and cx < bbox2[3])\n","\n","def merge_markers(in_markers, in_scores, in_labels, low_score=0.1, iou_thrd=0.4):\n","    delete_id = []\n","    for i in range(len(in_scores)):\n","        if (in_scores[i] <= low_score):\n","            delete_id.append(i)\n","    in_markers = np.delete(in_markers, delete_id, 0)\n","    in_scores = np.delete(in_scores, delete_id, 0)\n","    in_labels = np.delete(in_labels, delete_id, 0)\n","    delete_id = []\n","    for i in range(len(in_scores)):\n","        for j in range(i+1, len(in_scores)):\n","            iou = get_iou(in_markers[i], in_markers[j])\n","            if (iou >= iou_thrd):\n","                if (in_scores[i] > in_scores[j]):\n","                    delete_id.append(j)\n","                else:\n","                    delete_id.append(i)    \n","    out_markers = np.delete(in_markers, delete_id, 0)\n","    out_scores = np.delete(in_scores, delete_id, 0)\n","    out_labels = np.delete(in_labels, delete_id, 0)       \n","    return out_markers, out_scores, out_labels    "],"metadata":{"id":"q25V0QrNXiuJ","executionInfo":{"status":"ok","timestamp":1647872656470,"user_tz":240,"elapsed":419,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def score_froc(testset):\n","    #froc parameters\n","    hit_iou = 0.25\n","    min_score = 0.1\n","    num_images = 0.0\n","    num_lesions = 0.0\n","    froc_fp = np.zeros(1001)\n","    froc_sen = np.zeros(1001)\n","    loose_score = False\n","    label_id_offset = 1\n","    for image_features in testset:\n","#        filename = image_features['image/filename'].numpy()[0].decode(\"utf-8\") \n","        image_tensors, gt_boxes_list, gt_classes_list = GetImageLabelBoxTensors(image_features, 1)\n","        detections = detect(image_tensors[0])\n","                \n","        det_boxes = detections['detection_boxes'][0].numpy()\n","        det_labels = detections['detection_classes'][0].numpy().astype(np.uint32) + label_id_offset\n","        det_scores = detections['detection_scores'][0].numpy()\n","        out_boxes, out_scores, out_labels = merge_markers(det_boxes, det_scores, det_labels, low_score=min_score, iou_thrd=0.4)\n","        gt_boxes = gt_boxes_list[0].numpy()\n","        gt_labels = gt_classes_list\n","        num_det = len(out_scores)\n","        num_tru = len(gt_boxes)\n","        \n","        b_hit = False\n","        hits_score = []\n","        good_det_id = []\n","        for tru_id in range(num_tru):\n","            max_hit_score = 0.0\n","            for det_id in range(num_det):\n","                if loose_score:\n","                    b_hit = box1in2(out_boxes[det_id], gt_boxes[tru_id])\n","                else:\n","                    iou = get_iou(gt_boxes[tru_id], out_boxes[det_id])\n","                    b_hit = (iou >= hit_iou)\n","#                print('tru_id = {}, det_id = {}, iou = {}'.format(tru_id, det_id, iou))\n","                if b_hit:\n","                    max_hit_score = max(max_hit_score, out_scores[det_id])\n","                    good_det_id.append(det_id)\n","            hits_score.append(max_hit_score)\n","        hits_score = np.array(hits_score)\n","        good_det_id = np.unique(good_det_id).astype(np.int)\n","        fps_score = np.delete(out_scores, good_det_id, None)\n","        num_images += 1.0\n","        num_lesions += float(num_tru)\n","        print('{}: tru_boxes = {}, det_box = {}, hits_score = {}, fps_score = {}'.format(num_images, num_tru, num_det, len(hits_score), len(fps_score)))\n","            \n","        for t in range(0, 1001):\n","            th = t / 1000\n","            hit = len(hits_score[hits_score > th])\n","            fp = len(fps_score[fps_score > th])\n","            froc_sen[t] += hit\n","            froc_fp[t] += fp\n","        \n","        if (num_images <= 10):\n","            image_np = (image_tensors[0].numpy())[0]\n","            image_np = image_np.astype(np.uint8)\n","            gt_labels = np.ones_like(gt_classes_list[0].numpy().reshape((-1,))) * 99\n","            gt_scores = np.ones_like(gt_labels)\n","            gt_labels = gt_labels.astype(det_labels.dtype)\n","            out_boxes = np.concatenate((out_boxes, gt_boxes), axis=0)\n","            out_labels = np.concatenate((out_labels, gt_labels), axis=0)\n","            out_scores = np.concatenate((out_scores, gt_scores), axis=0)\n","            plot_detections(image_np, out_boxes, out_labels, out_scores, category_index, figsize=(15, 20), image_name=\"/content/drive/MyDrive/demo_\" + ('%02d' % num_images) + \".jpg\")\n","            \n","    froc_fp /= num_images\n","    froc_sen /= num_lesions\n","    with open(('/content/drive/MyDrive/froc.txt'), 'w') as fp:\n","        fp.write('number of lesion = {}, number of iamges = {}\\n'.format(int(num_lesions), int(num_images)))\n","        for i in range(0, 1001):\n","#            print('{:.4f}  {:.4f}'.format(froc_fp[i], froc_sen[i]))\n","            fp.write('{:.4f}  {:.4f}\\n'.format(froc_fp[i], froc_sen[i]))\n","        print('number of lesion = {}, number of iamges = {}'.format(int(num_lesions), int(num_images)))            \n","    plt.figure()\n","    plt.grid(b=True)\n","    plt.plot(froc_fp, froc_sen, 'b')\n","    plt.savefig('/content/drive/MyDrive/froc.png')\n","    print('high sensitivity = {}, total fp = {}'.format(froc_sen[0], froc_fp[0]))    \n","    return froc_fp, froc_sen"],"metadata":{"id":"zK6hsuxrYWzD","executionInfo":{"status":"ok","timestamp":1647874363698,"user_tz":240,"elapsed":340,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNYM8nL2Xzvq","executionInfo":{"status":"ok","timestamp":1647874431522,"user_tz":240,"elapsed":6162,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}},"outputId":"969b0990-e0fe-47d9-823c-eb15aec039be"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-21 14:53:45--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.203.128, 2607:f8b0:400e:c09::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.203.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 244817203 (233M) [application/x-tar]\n","Saving to: ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz.1’\n","\n","ssd_resnet50_v1_fpn 100%[===================>] 233.48M   200MB/s    in 1.2s    \n","\n","2022-03-21 14:53:46 (200 MB/s) - ‘ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz.1’ saved [244817203/244817203]\n","\n","mv: cannot move 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint' to 'models/research/object_detection/test_data/checkpoint': Directory not empty\n"]}]},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","print('Building model and restoring weights for fine-tuning...', flush=True)\n","num_classes = NUM_CLASSES\n","pipeline_config = 'models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n","checkpoint_path = get_latest_ckpt('/content/drive/MyDrive/my_model')\n","\n","# Load pipeline config and build a detection model.\n","#\n","# Since we are working off of a COCO architecture which predicts 90\n","# class slots by default, we override the `num_classes` field here to be just\n","# one (for our new rubber ducky class).\n","configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n","model_config = configs['model']\n","model_config.ssd.num_classes = num_classes\n","model_config.ssd.freeze_batchnorm = True\n","detection_model = model_builder.build(model_config=model_config, is_training=False)\n","\n","ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n","if (len(checkpoint_path) > 0):\n","    ckpt.restore(checkpoint_path).expect_partial()\n","\n","# Run model through a dummy image so that variables are created\n","image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n","prediction_dict = detection_model.predict(image, shapes)\n","_ = detection_model.postprocess(prediction_dict, shapes)\n","print('Weights restored!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDBedb6JX0X8","executionInfo":{"status":"ok","timestamp":1647872687314,"user_tz":240,"elapsed":10421,"user":{"displayName":"Zhong Tao","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15568032752507989555"}},"outputId":"2658e4b4-20fb-435c-a836-70d12233e659"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Building model and restoring weights for fine-tuning...\n","Weights restored!\n"]}]},{"cell_type":"code","source":["batch_size = 1\n","eval_tfr_path = ['/content/drive/MyDrive/data1/val_deeplesion.record-00028-of-00030']\n","testset = tf.data.TFRecordDataset(eval_tfr_path)\n","testset = testset.map(_parse_function)\n","testset = testset.batch(batch_size) \n","\n","tf.keras.backend.clear_session()\n","_, _ = score_froc(testset)"],"metadata":{"id":"FYF2jRf8X41K"},"execution_count":null,"outputs":[]}]}